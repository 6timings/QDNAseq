%\VignetteIndexEntry{An introduction to QDNAseq}

\documentclass{article}

\begin{document}

\title{Introduction to QDNAseq}
\author{Ilari Scheinin}
\maketitle

\section{Running QDNAseq}

First load the package.

<<reg>>=
library(qdnaseq)
@

Next we need the bin annotations. These are available pre-calculated for genome build hg19 and bin sizes 1, 5, 10, 15, 30, 50, 100, 500, and 1000 kbp. They can be loaded for example with:

<<reg, eval=FALSE>>=
bins <- getBinAnnotations(binsize=15)
@

If you are working with another genome build (or another species), see the section on generating the bin annotations.

To load all the bam files in the current directory, run:

<<reg, echo=TRUE, eval=FALSE>>=
readCounts <- binReadCounts(bins)
# all files ending in .bam from the current working directory

# or

readCounts <- binReadCounts(bins, bamfiles='tumor.bam')
# file 'tumor.bam' from the current working directory

# or

readCounts <- binReadCounts(bins, path='tumors')
# all files ending in .bam from the subdirectory 'tumors'
@

For the purpose of this tutorial, we load the example data set of chromosome 9 of low grade glioma sample LGG150.

<<reg>>=
data(LGG150)
@

Plot median read counts as a function of GC content and mappability. As the example data set only contains chromosome 9 and not the whole genome, this looks jagged. Normally, a smoother distribution is to be expected.

<<label=readcounts,include=FALSE>>=
readCountPlot(LGG150)
@

\begin{figure}
\begin{center}
<<label=readcounts,fig=TRUE,echo=FALSE>>=
<<readcounts>>
@
\end{center}
\caption{A plot}
\label{fig:readcounts}
\end{figure}


Perform correction for GC content and mappability.

<<reg>>=
LGG150 <- correctBins(LGG150)
@

Perform median normalization.

<<reg>>=
LGG150 <- normalizeBins(LGG150)
@

To apply filtering, plot the profile and highlight bins to be filtered out for evaluation. By default, bins with mappabilities lower than 50 and the 1000 Genomes residuals larger than 2 standard deviations are filtered out.

% png? https://stat.ethz.ch/pipermail/r-help/2009-November/218795.html

<<label=filters,include=FALSE>>=
plot(LGG150)
highlightFilters(LGG150, mappability=50, blacklist=0, residual=2, bases=0)
@

\begin{figure}
\begin{center}
<<label=filters,fig=TRUE,echo=FALSE>>=
<<filters>>
@
\end{center}
\caption{A plot}
\label{fig:filters}
\end{figure}

Apply filters.

<<reg>>=
LGG150 <- applyFilters(LGG150, mappability=50, blacklist=0, residual=2,
  bases=0)
@

Data now ready to be analyzed with a downstream package of choice. Segmentation with the CBS algorithm from DNAcopy and calling copy number aberrations with CGHcall have been implemented for convenience.

<<reg>>=
LGG150 <- segmentBins(LGG150)
@

Plot to evaluate segmentation.

<<label=segmentation,include=FALSE>>=
plot(LGG150)
@

\begin{figure}
\begin{center}
<<label=segmentation,fig=TRUE,echo=FALSE>>=
<<segmentation>>
@
\end{center}
\caption{A plot}
\label{fig:segmentation}
\end{figure}

Tune segmentation parameters and iterate until satisfied. Next, perform mode normalization and call aberrations, and plot the final results.

<<reg>>=
LGG150 <- callBins(LGG150)
@

<<label=calls,include=FALSE>>=
plot(LGG150)
@

\begin{figure}
\begin{center}
<<label=calls,fig=TRUE,echo=FALSE>>=
<<calls>>
@
\end{center}
\caption{A plot}
\label{fig:calls}
\end{figure}

Finally, for other downstream analyses, such as running CGHregions, it might be useful to convert to a cghCall object.

<<reg>>=
cgh <- makeCgh(LGG150)
@

% caching

% 661 bam files = 445G
% cache/reads = 13G
% cache/readCounts/15kbp = 139M
% cache/readCounts/30kbp = 82M
% cache/readCounts/100kbp = 32M
% cache/readCounts/1000kbp = 5.2M

\section{Generating bin annotations}

<<reg, eval=FALSE>>=
library(qdnaseq)
library(BSgenome.Hsapiens.UCSC.hg19)

binsize <- 15

bins <- createBins(bsgenome=BSgenome.Hsapiens.UCSC.hg19, binsize=binsize)
bins$mappability <- calculateMappability(bins,
  bigWigFile='/path/to/wgEncodeCrgMapabilityAlign50mer.bigWig',
  bigWigAverageOverBed='/path/to/bigWigAverageOverBed')
bins$blacklist <- calculateBlacklist(bins,
  bedFiles=c('/path/to/wgEncodeDacMapabilityConsensusExcludable.bed',
  '/path/to/wgEncodeDukeMapabilityRegionsExcludable.bed'))
tg <- binReadCounts(bins,
  path='/path/to/1000Genomes/bam/files')
tg <- correctBins(tg)
bins$residual <- apply(Biobase::assayDataElement(tg, 'residuals'), 1,
  median, na.rm=TRUE)
bins <- AnnotatedDataFrame(bins,
  varMetadata=data.frame(labelDescription=c(
  'Chromosome name',
  'Base pair start position',
  'Base pair end position',
  'Percentage of non-N nucleotides (of full bin size)',
  'Percentage of C and G nucleotides (of non-N nucleotides)',
  'Average mappability of 50mers with a maximum of 2 mismatches',
  'Percent overlap with ENCODE blacklisted regions',
  'Median loess residual from 1000 Genomes (50mers)'),
  rownames=colnames(bins)))
@

% where to download ENCODE
% how 1000 genomes were downloaded

\end{document}

% EOF
